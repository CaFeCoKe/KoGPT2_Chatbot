{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KoGPT2_Chatbot.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Xk_nqSTrbwKrGt694-11yEat29HV099O","authorship_tag":"ABX9TyMuC+UumZuom+sQBUGj7/yT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 트랜스포머 설치"],"metadata":{"id":"CpMQfUYbefMO"}},{"cell_type":"code","execution_count":23,"metadata":{"id":"oQLnQvvyeEtR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651327803224,"user_tz":-540,"elapsed":3173,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"8e311712-d1b5-48bb-f40e-98de4296fd22"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","source":["# 말뭉치 다운로드"],"metadata":{"id":"Hn0nnm2TfD2x"}},{"cell_type":"code","source":["import pandas as pd\n","from tqdm import tqdm\n","import urllib.request"],"metadata":{"id":"0I9NrEcGqzaA","executionInfo":{"status":"ok","timestamp":1651327803224,"user_tz":-540,"elapsed":10,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n","chat_data = pd.read_csv('ChatBotData.csv')"],"metadata":{"id":"7qbWemiLq0lG","executionInfo":{"status":"ok","timestamp":1651327803225,"user_tz":-540,"elapsed":11,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["chat_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Y8dupj8eq7-O","executionInfo":{"status":"ok","timestamp":1651327803668,"user_tz":-540,"elapsed":453,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"fc050454-4176-446e-ca1a-a62e4f503c00"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 Q            A  label\n","0           12시 땡!   하루가 또 가네요.      0\n","1      1지망 학교 떨어졌어    위로해 드립니다.      0\n","2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n","3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n","4          PPL 심하네   눈살이 찌푸려지죠.      0"],"text/html":["\n","  <div id=\"df-846c9799-8b75-4a6f-a4ed-e971c07da821\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-846c9799-8b75-4a6f-a4ed-e971c07da821')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-846c9799-8b75-4a6f-a4ed-e971c07da821 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-846c9799-8b75-4a6f-a4ed-e971c07da821');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["len(chat_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8XGf4UFNrc9","executionInfo":{"status":"ok","timestamp":1651327803669,"user_tz":-540,"elapsed":18,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"48dd2ef4-25e5-49f1-c3c3-15d936ec909f"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11823"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["# 토크나이저 준비\n","\n","`PreTrainedTokenizerFast`를 사용하여 KoGPT2의 Tokenizer 설정 정보를 불러온다."],"metadata":{"id":"jQPHF9yneiVV"}},{"cell_type":"code","source":["from transformers import PreTrainedTokenizerFast"],"metadata":{"id":"-lCcRUlGeo3L","executionInfo":{"status":"ok","timestamp":1651327803670,"user_tz":-540,"elapsed":17,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["tokenizer = PreTrainedTokenizerFast.from_pretrained(\n","    \"skt/kogpt2-base-v2\",\n","    bos_token='</s>',       # 문장 시작토큰\n","    eos_token='</s>',       # 문장 마지막토큰\n","    unk_token='<unk>',      # 어휘에 없는 토큰\n","    pad_token='<pad>',      # 크기 맞추기 토큰\n","    mask_token='<mask>',     # 마스킹 토큰\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bz6QepaperYG","executionInfo":{"status":"ok","timestamp":1651327803670,"user_tz":-540,"elapsed":16,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"b829615b-0fa1-4856-a7c3-4247a9112fec"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}]},{"cell_type":"markdown","source":["스페셜 토큰 확인"],"metadata":{"id":"2d7m-pfsuwnR"}},{"cell_type":"code","source":["for i in range (10):\n","    print(\"index : \",i,\" =  tokens : \",tokenizer.decode(i))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81xlMWbftZgt","executionInfo":{"status":"ok","timestamp":1651327803671,"user_tz":-540,"elapsed":15,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"2ae6dc44-9efd-4675-902a-e8da99e551b6"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["index :  0  =  tokens :  <s>\n","index :  1  =  tokens :  </s>\n","index :  2  =  tokens :  <usr>\n","index :  3  =  tokens :  <pad>\n","index :  4  =  tokens :  <sys>\n","index :  5  =  tokens :  <unk>\n","index :  6  =  tokens :  <mask>\n","index :  7  =  tokens :  <d>\n","index :  8  =  tokens :  </d>\n","index :  9  =  tokens :  <unused0>\n"]}]},{"cell_type":"markdown","source":["# 토크나이징, 데이터 구축\n","\n","`</s>` `<usr>` 유저 질문 `<sys>` 모델 답변 `</s>` `<pad>`..."],"metadata":{"id":"ctu47Xcmw4vn"}},{"cell_type":"code","source":["import numpy as np\n","from dataclasses import dataclass\n","from typing import List, Optional\n","import torch\n","from torch.utils.data import Dataset"],"metadata":{"id":"1j7UK-Xufe38","executionInfo":{"status":"ok","timestamp":1651327803671,"user_tz":-540,"elapsed":14,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","@dataclass\n","class Features:\n","    token_ids: List[int]\n","    attention_mask: Optional[List[int]] = None\n","    token_type_ids: Optional[List[int]] = None\n","    label_ids: Optional[List[int]] = None\n","\"\"\""],"metadata":{"id":"E65ztzFtV-lA","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1651327803671,"user_tz":-540,"elapsed":13,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"68148e80-a7a0-4965-fea5-0b6885905ed9"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n@dataclass\\nclass Features:\\n    token_ids: List[int]\\n    attention_mask: Optional[List[int]] = None\\n    token_type_ids: Optional[List[int]] = None\\n    label_ids: Optional[List[int]] = None\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# 챗봇 데이터를 처리하는 클래스\n","class ChatbotDataset(Dataset):\n","    def __init__(self, chats, max_len=50):  # 데이터셋의 전처리를 해주는 부분\n","        self._data = chats\n","        self.max_len = max_len\n","        self.q_token = \"<usr>\"\n","        self.a_token = \"<sys>\"\n","        self.bos = tokenizer.bos_token\n","        self.eos = tokenizer.eos_token\n","        self.mask = tokenizer.mask_token\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):  # chatbotdata 의 길이를 리턴\n","        return len(self._data)\n","\n","    def __getitem__(self, idx):  # 로드한 챗봇 데이터를 차례차례 DataLoader로 넘겨주는 메서드\n","        index = self._data.iloc[idx]\n","\n","        q = index[\"Q\"]  # 질문\n","        q_toked = self.tokenizer.tokenize(self.bos + self.q_token + q)      # </s> <usr> 질문\n","        q_len = len(q_toked)\n","\n","        a = index[\"A\"]  # 답변\n","        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)      # <sys> 답 </s>\n","        a_len = len(a_toked)\n","\n","        # 질문의 길이가 최대길이보다 클때\n","        if q_len > self.max_len: \n","            q_toked = q_toked[-(int(self.max_len / 2)):]   # 질문길이를 최대길이의 반으로 \n","            q_len = len(q_toked)\n","            \"\"\"\n","            a_len = self.max_len - q_len              # 답변의 길이를 최대길이 - 질문길이\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","            \"\"\"\n","\n","        # 질문 + 답변 길이가 최대길이보다 클때\n","        if q_len + a_len > self.max_len:\n","            a_len = self.max_len - q_len        # 답변의 길이 = 최대길이 - 질문길이\n","\n","            if a_len <= 0:       # 질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]   # 질문길이를 최대길이의 반으로 \n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len              # 답변의 길이를 최대길이 - 질문길이\n","                \n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        # 질문 + 답변을 index로 변환   \n","        token = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n","        # 최대길이만큼 padding\n","        while len(token) < self.max_len:\n","            token += [self.tokenizer.pad_token_id]\n","\n","        # attention(어텐션마스크) = 질문+답변 길이 1 + 나머지(패딩) 0\n","        attention = [1]*(q_len+a_len) + [0]*(self.max_len - q_len - a_len)\n","\n","        # token_type_ids(세그먼트 정보) = 질문길이 0 + 답변길이 1 + 나머지 0\n","        token_type = [0]*q_len + [1]*a_len + [0]*(self.max_len - q_len - a_len)\n","\n","        # labels(답변) = [<mask>, <mask>, ...., <mask>, ..., <sys>,..답변.. </s>, <pad>....]\n","        labels = [self.mask,] * q_len + a_toked[0:]\n","        # index로 변환\n","        labels = self.tokenizer.convert_tokens_to_ids(labels)\n","        # 최대길이만큼 padding\n","        while len(labels) < self.max_len:\n","            labels += [self.tokenizer.pad_token_id]\n","\n","        \"\"\"\n","        features = []    \n","        feature = Features(\n","            token_ids = token, attention_mask = attention, token_type_ids = token_type, label_ids = labels\n","        )\n","        features.append(feature)\n","        \"\"\"\n","        # 질문 + 답변, 어텐션마스크, 세그먼트 정보, 답변\n","        # return features\n","        return (token, attention, token_type, labels)"],"metadata":{"id":"Cl6t9n2FwRpP","executionInfo":{"status":"ok","timestamp":1651327803672,"user_tz":-540,"elapsed":13,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["데이터셋 구축\n","\n","구성 : token_ids, attention_mask, token_type_ids, label_ids)"],"metadata":{"id":"ulVl4nAqdbC_"}},{"cell_type":"code","source":["chat_dataset = ChatbotDataset(chat_data, max_len=50)"],"metadata":{"id":"Mk9RZtNFMnet","executionInfo":{"status":"ok","timestamp":1651327803672,"user_tz":-540,"elapsed":12,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["for n in range(3):\n","    print(\"chat_dataset[\",n,\"]\")\n","    print(\"token_ids      : \", chat_dataset[n][0])\n","    print(\"attention_mask : \", chat_dataset[n][1])\n","    print(\"token_type_ids : \", chat_dataset[n][2])\n","    print(\"label_ids      : \", chat_dataset[n][3],\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyaCWaTeMocf","executionInfo":{"status":"ok","timestamp":1651327803947,"user_tz":-540,"elapsed":287,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"cae6d8fc-56fb-4c0e-94f1-1b8bbc4f48c0"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["chat_dataset[ 0 ]\n","token_ids      :  [1, 2, 9349, 7888, 739, 7318, 376, 4, 12557, 6824, 9108, 9028, 7098, 25856, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","attention_mask :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","token_type_ids :  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","label_ids      :  [6, 6, 6, 6, 6, 6, 6, 4, 12557, 6824, 9108, 9028, 7098, 25856, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n","\n","chat_dataset[ 1 ]\n","token_ids      :  [1, 2, 9020, 8263, 7497, 10192, 11615, 8210, 8006, 4, 12422, 8711, 9535, 7483, 12521, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","attention_mask :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","token_type_ids :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","label_ids      :  [6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 12422, 8711, 9535, 7483, 12521, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n","\n","chat_dataset[ 2 ]\n","token_ids      :  [1, 2, 9085, 7597, 395, 8149, 10624, 7397, 24224, 13358, 7182, 4, 12079, 8135, 16899, 9677, 8234, 389, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n","attention_mask :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","token_type_ids :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","label_ids      :  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 12079, 8135, 16899, 9677, 8234, 389, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3] \n","\n"]}]},{"cell_type":"markdown","source":["데이터로더 구축"],"metadata":{"id":"nGHLFUMtBZih"}},{"cell_type":"code","source":["# collate_fn 구성\n","def collate_batch(batch):\n","    token_ids = [item[:][0] for item in batch]\n","    attention_mask = [item[:][1] for item in batch]\n","    token_tpye_ids = [item[:][2] for item in batch]\n","    label_ids = [item[:][3] for item in batch]\n","\n","    return torch.LongTensor(token_ids), torch.LongTensor(attention_mask), torch.LongTensor(token_tpye_ids), torch.LongTensor(label_ids)"],"metadata":{"id":"FI7odUN0BCUG","executionInfo":{"status":"ok","timestamp":1651327803948,"user_tz":-540,"elapsed":7,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler"],"metadata":{"id":"XccVWvqGXrIi","executionInfo":{"status":"ok","timestamp":1651327803948,"user_tz":-540,"elapsed":7,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["chat_dataloader = DataLoader(\n","    chat_dataset,\n","    batch_size = 32,\n","    sampler = RandomSampler(chat_dataset, replacement=False),\n","    collate_fn = collate_batch,\n","    drop_last = False,\n","    num_workers = 0,\n",")"],"metadata":{"id":"Je9XoYCNA-lJ","executionInfo":{"status":"ok","timestamp":1651327803948,"user_tz":-540,"elapsed":7,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# 데이터로더 확인\n","sample_data = iter(chat_dataloader)\n","sample_ids = next(sample_data)\n","\n","token_ids, attention_mask, token_type_ids, label_ids = sample_ids\n","\n","print(\"first item of batch (chat_dataloader)\")\n","print(\"token_ids \\n\", token_ids[:][0], token_ids.size(),\"\\n\")\n","print(\"attention_mask \\n\", attention_mask[:][0], attention_mask.size(),\"\\n\")\n","print(\"token_type_ids \\n\", token_type_ids[:][0], token_type_ids.size(),\"\\n\")\n","print(\"label_ids \\n\", label_ids[:][0], label_ids.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bd60p-dkA_wP","executionInfo":{"status":"ok","timestamp":1651327803949,"user_tz":-540,"elapsed":7,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"ce12b740-487f-4a87-83c2-9d8464081615"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["first item of batch (chat_dataloader)\n","token_ids \n"," tensor([    1,     2, 20294, 13554, 10056,  7898,  8006,   389,     4, 10203,\n","         7216, 11595,  8267,  9122,  8046, 25856,     1,     3,     3,     3,\n","            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","            3,     3,     3,     3,     3,     3,     3,     3,     3,     3]) torch.Size([32, 50]) \n","\n","attention_mask \n"," tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0]) torch.Size([32, 50]) \n","\n","token_type_ids \n"," tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0]) torch.Size([32, 50]) \n","\n","label_ids \n"," tensor([    6,     6,     6,     6,     6,     6,     6,     6,     4, 10203,\n","         7216, 11595,  8267,  9122,  8046, 25856,     1,     3,     3,     3,\n","            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","            3,     3,     3,     3,     3,     3,     3,     3,     3,     3]) torch.Size([32, 50])\n"]}]},{"cell_type":"markdown","source":["# 모델 학습\n","\n","모델 준비 및 설정 초기화"],"metadata":{"id":"Zl9l1SbCZlaj"}},{"cell_type":"code","source":["import torch.nn\n","from transformers import GPT2LMHeadModel"],"metadata":{"id":"svqblhjyZlED","executionInfo":{"status":"ok","timestamp":1651327803949,"user_tz":-540,"elapsed":6,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"],"metadata":{"id":"O1q0bK3VZpCk","executionInfo":{"status":"ok","timestamp":1651327805909,"user_tz":-540,"elapsed":1965,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","epoch = 1\n","learning_rate = 3e-5\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","Sneg = -1e18"],"metadata":{"id":"dz6uytASZqUT","executionInfo":{"status":"ok","timestamp":1651327805910,"user_tz":-540,"elapsed":9,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["모델 구성 확인 및 훈련모드 설정"],"metadata":{"id":"xszA0xPSoMIE"}},{"cell_type":"code","source":["model.to(device)\n","model.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RGe69UAqg7_p","executionInfo":{"status":"ok","timestamp":1651327805910,"user_tz":-540,"elapsed":7,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"4e617cea-d9b8-4062-dc17-e2c9e65c2013"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51200, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",")"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["학습 진행"],"metadata":{"id":"WDb1ndGLoFeM"}},{"cell_type":"code","source":["model.train()\n","\n","for epoch in range(epoch):\n","    loss = 0.0\n","    avg_loss = 0.0\n","    \n","    for batch_idx, samples in enumerate(tqdm(chat_dataloader)):\n","        optimizer.zero_grad()       # optimizer 초기화(Gradient)\n","\n","        token_ids, attention_mask, token_type_ids, label_ids = samples\n","        token_ids = token_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        token_type_ids = token_type_ids.to(device)\n","        label_ids = label_ids.to(device)\n","\n","        out = model(\n","            input_ids=token_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            labels=label_ids,\n","            )\n","        \n","        loss += out.loss\n","        out = out.logits\n","        \n","        #mask_3d = token_ids.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        #mask_out = torch.where(mask_3d == 1, out, (Sneg * torch.ones_like(out)))\n","\n","        #loss = criterion(mask_out.transpose(2, 1), token_ids)\n","\n","        #loss.backward()\n","        \"\"\"\n","        # 평균 loss = loss 정규화\n","        avg_loss = loss.sum() / token_type_ids.sum()\n","        avg_loss.backward()\n","        \"\"\"\n","        #optimizer.step()\n","        #avg_loss += loss.item()\n","        torch.cuda.empty_cache()\n","\n","    avg_loss = loss / batch_idx\n","    \n","    print(f'epoch: {epoch}, loss: {avg_loss}')"],"metadata":{"id":"f9B0N7-7Zrgq","colab":{"base_uri":"https://localhost:8080/","height":437},"executionInfo":{"status":"error","timestamp":1651327807212,"user_tz":-540,"elapsed":1308,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"78873594-bcb9-44be-8364-f30a82a51dfa"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["  1%|▏         | 5/370 [00:01<01:18,  4.65it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-a44c8490b258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m         )\n\u001b[1;32m   1062\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m                 )\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 190\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2484\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         )\n\u001b[0;32m-> 2486\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.76 GiB total capacity; 12.73 GiB already allocated; 11.75 MiB free; 13.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"markdown","source":["# 챗봇 실행"],"metadata":{"id":"gYC2gZOaoaKN"}},{"cell_type":"code","source":["while 1:\n","    q = input(\"user > \").strip()\n","    if q == \"quit\":\n","        break\n","    a = \"\"\n","\n","    #input_ids = tokenizer.encode(tokenizer.bos_token + \"<usr>\" + q + \"<sys>\" + a, return_tensors=\"pt\").to(device)\n","    input_ids = tokenizer.encode(q, return_tensors=\"pt\").to(device)\n","\n","    with torch.no_grad():\n","        gen_ids = model.generate(\n","        input_ids,\n","        max_length=30,\n","        repetition_penalty=1.2,\n","        use_cache=True,\n","        )\n","    \n","    generated = tokenizer.decode([el.item() for el in gen_ids[0]])   # gererated_ids를 텍스트로 변환\n","\n","    print(generated)"],"metadata":{"id":"JUR14fz8oB0l","executionInfo":{"status":"aborted","timestamp":1651327807212,"user_tz":-540,"elapsed":5,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":null,"outputs":[]}]}